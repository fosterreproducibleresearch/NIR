{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c02a0ab-71d8-4d71-897c-0e11c70a4481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example\n",
      "\n",
      "\n",
      "Running `<function read_embs>`...\n",
      "Function read_embs with  Args:[<class 'str'>] | Kwargs:{} took 0.0128 seconds\n",
      "Probability that `animals#eagle01` is an instance of `¬Penguin ⊓ ∀ hasCovering.Feathers` is 0.9999998807907104\n",
      "\n",
      "\n",
      "Second example\n",
      "\n",
      "Probability that `animals#eel01` is an instance of `(¬Eel) ⊓ (¬Bird)` is 9.744724138727179e-07\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from nir.models import NIRTransformer\n",
    "from nir.config import NIRConfig\n",
    "from nir.utils import read_embs\n",
    "AutoConfig.register(\"nir\", NIRConfig)\n",
    "AutoModel.register(NIRConfig, NIRTransformer)\n",
    "pretrained_model_path = \"nir_pretrained_models/NIR_Transformer_animals\"\n",
    "model = AutoModel.from_pretrained(f\"{pretrained_model_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{pretrained_model_path}\")\n",
    "\n",
    "print(\"First example\\n\")\n",
    "class_expression = \"¬Penguin ⊓ ∀ hasCovering.Feathers\"\n",
    "individual = \"animals#eagle01\"\n",
    "embeddings = read_embs(\"./datasets/animals/\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "inputs = tokenizer([class_expression], padding=\"max_length\", truncation=True, max_length=model.max_length, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "ind_embs = torch.FloatTensor(embeddings.loc[individual].values).unsqueeze(0).to(device)\n",
    "\n",
    "probability = model(input_ids, attention_mask, ind_embs)\n",
    "\n",
    "print(f\"Probability that `{individual}` is an instance of `{class_expression}` is {probability}\")\n",
    "\n",
    "\n",
    "## Other example\n",
    "print(\"\\n\\nSecond example\\n\")\n",
    "class_expression = \"(¬Eel) ⊓ (¬Bird)\"\n",
    "individual = \"animals#eel01\"\n",
    "ind_embs = torch.FloatTensor(embeddings.loc[individual].values).unsqueeze(0).to(device)\n",
    "inputs = tokenizer([class_expression], padding=\"max_length\", truncation=True, max_length=model.max_length, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "probability = model(input_ids, attention_mask, ind_embs)\n",
    "\n",
    "print(f\"Probability that `{individual}` is an instance of `{class_expression}` is {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ad337-f0be-476c-b486-539d3cbdbba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nir",
   "language": "python",
   "name": "nir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
